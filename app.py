import streamlit as st
import pickle
import pandas as pd
import numpy as np
import xgboost as xgb
import shap
import matplotlib.pyplot as plt
import time
from pathlib import Path
import joblib
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# é¡µé¢è®¾ç½®
st.set_page_config(page_title="KOA æ‚£è€…è¡°å¼±é£é™©é¢„æµ‹", layout="centered")
st.title("ğŸ©º è†éª¨å…³èŠ‚ç‚æ‚£è€…è¡°å¼±é£é™©é¢„æµ‹ç³»ç»Ÿ")
st.markdown("æ ¹æ®è¾“å…¥çš„ä¸´åºŠç‰¹å¾ï¼Œé¢„æµ‹è†å…³èŠ‚éª¨å…³èŠ‚ç‚ï¼ˆKOAï¼‰æ‚£è€…å‘ç”Ÿè¡°å¼±ï¼ˆFrailtyï¼‰çš„æ¦‚ç‡ï¼Œå¹¶å¯è§†åŒ–å†³ç­–ä¾æ®ã€‚")

# è‡ªå®šä¹‰CSSå®ç°å…¨é¡µé¢å±…ä¸­
st.markdown(
    """
    <style>
    .main > div {
        max-width: 800px;
        padding-left: 5rem;
        padding-right: 5rem;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# åŠ è½½æ¨¡å‹å’Œç»„ä»¶
@st.cache_resource
def load_components():
    try:
        base_path = Path(__file__).parent
        components = {}
        
        # å°è¯•åŠ è½½é¢„å¤„ç†å™¨
        try:
            preprocessor_path = base_path / "frailty_preprocessor28.pkl"
            if preprocessor_path.exists():
                with open(preprocessor_path, 'rb') as f:
                    components['preprocessor'] = pickle.load(f)
                st.success("âœ… é¢„å¤„ç†å™¨åŠ è½½æˆåŠŸ")
            else:
                st.warning("âš ï¸ é¢„å¤„ç†å™¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨å†…ç½®é¢„å¤„ç†é€»è¾‘")
        except Exception as e:
            st.warning(f"âš ï¸ é¢„å¤„ç†å™¨åŠ è½½å¤±è´¥: {str(e)}")
        
        # å°è¯•åŠ è½½æ¨¡å‹
        try:
            model_path = base_path / "frailty_xgb_model28.pkl"
            if model_path.exists():
                components['model'] = joblib.load(model_path)
                st.success("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                st.error("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
                return None
        except Exception as e:
            st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return None
        
        # å°è¯•åŠ è½½é¢„æµ‹å™¨
        try:
            predictor_path = base_path / "frailty_predictor28.pkl"
            if predictor_path.exists():
                with open(predictor_path, 'rb') as f:
                    components['predictor'] = pickle.load(f)
                st.success("âœ… é¢„æµ‹å™¨åŠ è½½æˆåŠŸ")
            else:
                st.warning("âš ï¸ é¢„æµ‹å™¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨é»˜è®¤é˜ˆå€¼0.57")
        except Exception as e:
            st.warning(f"âš ï¸ é¢„æµ‹å™¨åŠ è½½å¤±è´¥: {str(e)}")
        
        return components
        
    except Exception as e:
        st.error(f"âŒ ç»„ä»¶åŠ è½½å¤±è´¥: {str(e)}")
        st.write("å½“å‰ç›®å½•å†…å®¹:", [f.name for f in base_path.glob('*')])
        return None

components = load_components()

if components is None or 'model' not in components:
    st.error("æ— æ³•åŠ è½½å¿…è¦çš„æ¨¡å‹ç»„ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
    st.stop()

model = components['model']
preprocessor = components.get('preprocessor')
predictor = components.get('predictor')

# å¦‚æœæ²¡æœ‰é¢„å¤„ç†å™¨ï¼Œåˆ›å»ºå†…ç½®çš„é¢„å¤„ç†é€»è¾‘
if preprocessor is None:
    # å®šä¹‰ç‰¹å¾å¤„ç†
    numeric_features = ['age', 'bmi', 'crp', 'hgb']
    categorical_features = ['gender', 'smoking', 'fall', 'activity', 'complication', 'daily_activity', 'sit_stand']
    
    numeric_transformer = StandardScaler()
    categorical_transformer = OneHotEncoder(handle_unknown='ignore')
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ])

# åˆå§‹åŒ–SHAPè§£é‡Šå™¨
@st.cache_resource
def create_explainer(_model, _preprocessor):
    try:
        # åˆ›å»ºç¤ºä¾‹æ•°æ®æ¥æ‹Ÿåˆé¢„å¤„ç†å™¨ï¼ˆå¦‚æœæ²¡æœ‰å·²ç»æ‹Ÿåˆï¼‰
        if not hasattr(_preprocessor, 'transform'):
            example_data = pd.DataFrame({
                'gender': ['ç”·'], 'age': [65], 'smoking': ['å¦'], 'bmi': [24.5],
                'fall': ['å¦'], 'activity': ['ä¸­'], 'complication': ['æ²¡æœ‰'],
                'daily_activity': ['æ— é™åˆ¶'], 'sit_stand': ['å°äº12s'],
                'crp': [3.2], 'hgb': [132.5]
            })
            _preprocessor.fit(example_data)
        
        # åˆ›å»ºè§£é‡Šå™¨
        if hasattr(_model, 'predict_proba'):
            return shap.TreeExplainer(_model, model_output="probability")
        else:
            return shap.TreeExplainer(_model, model_output="margin")
    except Exception as e:
        st.warning(f"SHAPè§£é‡Šå™¨åˆ›å»ºå¤±è´¥: {str(e)}")
        return None

explainer = create_explainer(model, preprocessor)

# åˆ›å»ºè¾“å…¥è¡¨å•
with st.form("patient_input_form"):
    st.markdown("---")
    st.subheader("ğŸ“‹ è¯·å¡«å†™ä»¥ä¸‹ä¿¡æ¯") 
    
    col1, col2 = st.columns(2)
    
    with col1:
        gender = st.radio("æ‚¨çš„æ€§åˆ«", ["ç”·", "å¥³"])
        age = st.number_input("æ‚¨çš„å¹´é¾„ï¼ˆå²ï¼‰", min_value=0, max_value=120, value=65)
        smoking = st.radio("æ‚¨æ˜¯å¦å¸çƒŸï¼Ÿ", ["å¦", "æ˜¯"])
        bmi = st.number_input("BMIï¼ˆkg/mÂ²ï¼‰", min_value=10.0, max_value=50.0, value=24.5, step=0.1)
        fall = st.radio("è¿‡å»ä¸€å¹´æ˜¯å¦è·Œå€’ï¼Ÿ", ["å¦", "æ˜¯"])
    
    with col2:
        activity = st.radio("ä½“åŠ›æ´»åŠ¨æ°´å¹³", ["é«˜", "ä¸­", "ä½"])
        complication = st.radio("å¹¶å‘ç—‡æ•°é‡", ["æ²¡æœ‰", "1ä¸ª", "è‡³å°‘2ä¸ª"])
        daily_activity = st.radio("æ—¥å¸¸ç”Ÿæ´»èƒ½åŠ›", ["æ— é™åˆ¶", "æœ‰é™åˆ¶"])
        sit_stand = st.radio("5æ¬¡åç«‹æ—¶é—´", ["å°äº12s", "å¤§äºç­‰äº12s"])
        crp = st.number_input("Cååº”è›‹ç™½ï¼ˆmg/Lï¼‰", min_value=0.0, max_value=100.0, value=3.2, step=0.1)
        hgb = st.number_input("è¡€çº¢è›‹ç™½ï¼ˆg/Lï¼‰", min_value=0.0, max_value=200.0, value=132.5, step=0.1)
        
    submitted = st.form_submit_button("å¼€å§‹è¯„ä¼°")

# æ‰‹åŠ¨ç¼–ç å‡½æ•°ï¼ˆå¦‚æœé¢„å¤„ç†å™¨ä¸å¯ç”¨ï¼‰
def manual_preprocess(input_df):
    # æ•°å€¼ç‰¹å¾æ ‡å‡†åŒ–
    numeric_features = ['age', 'bmi', 'crp', 'hgb']
    for feature in numeric_features:
        input_df[feature] = (input_df[feature] - input_df[feature].mean()) / input_df[feature].std()
    
    # åˆ†ç±»ç‰¹å¾one-hotç¼–ç 
    categorical_mapping = {
        'gender': {'ç”·': [1, 0], 'å¥³': [0, 1]},
        'smoking': {'å¦': [1, 0], 'æ˜¯': [0, 1]},
        'fall': {'å¦': [1, 0], 'æ˜¯': [0, 1]},
        'activity': {'é«˜': [1, 0, 0], 'ä¸­': [0, 1, 0], 'ä½': [0, 0, 1]},
        'complication': {'æ²¡æœ‰': [1, 0, 0], '1ä¸ª': [0, 1, 0], 'è‡³å°‘2ä¸ª': [0, 0, 1]},
        'daily_activity': {'æ— é™åˆ¶': [1, 0], 'æœ‰é™åˆ¶': [0, 1]},
        'sit_stand': {'å°äº12s': [1, 0], 'å¤§äºç­‰äº12s': [0, 1]}
    }
    
    processed_features = []
    for col in input_df.columns:
        if col in categorical_mapping:
            values = categorical_mapping[col][input_df[col].iloc[0]]
            for i, val in enumerate(values):
                processed_features.append(val)
        elif col in numeric_features:
            processed_features.append(input_df[col].iloc[0])
    
    return np.array([processed_features])

# å¤„ç†è¾“å…¥æ•°æ®å¹¶é¢„æµ‹
if submitted:
    with st.spinner('æ­£åœ¨è®¡ç®—...'):
        time.sleep(0.5)
        
        # åˆ›å»ºåŸå§‹è¾“å…¥æ•°æ®
        input_data = {
            'gender': gender,
            'age': age,
            'smoking': smoking,
            'bmi': bmi,
            'fall': fall,
            'activity': activity,
            'complication': complication,
            'daily_activity': daily_activity,
            'sit_stand': sit_stand,
            'crp': crp,
            'hgb': hgb
        }
        
        # è½¬æ¢ä¸ºDataFrame
        input_df = pd.DataFrame([input_data])
        
        try:
            # é¢„å¤„ç†æ•°æ®
            if hasattr(preprocessor, 'transform'):
                processed_data = preprocessor.transform(input_df)
            else:
                processed_data = manual_preprocess(input_df)
            
            # è¿›è¡Œé¢„æµ‹
            if predictor is not None and hasattr(predictor, 'predict_proba'):
                proba = predictor.predict_proba(input_df)[0, 1]
                prediction = predictor.predict(input_df)[0]
            else:
                if hasattr(model, 'predict_proba'):
                    proba = model.predict_proba(processed_data)[0, 1]
                    prediction = (proba >= 0.57).astype(int)
                else:
                    raw_pred = model.predict(processed_data)[0]
                    proba = 1 / (1 + np.exp(-raw_pred))
                    prediction = 1 if proba >= 0.57 else 0
            
            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            st.success(f"ğŸ“Š é¢„æµ‹ç»“æœ: æ‚£è€…è¡°å¼±æ¦‚ç‡ä¸º {proba*100:.2f}%")
            
            # é£é™©è¯„ä¼°
            if prediction == 1:
                st.error("""âš ï¸ **é«˜é£é™©ï¼šå»ºè®®ç«‹å³ä¸´åºŠå¹²é¢„**""")
                st.write("- æ¯å‘¨éšè®¿ç›‘æµ‹")
                st.write("- å¿…é¡»ç‰©ç†æ²»ç–—å¹²é¢„")
                st.write("- å…¨é¢è¯„ä¼°å¹¶å‘ç—‡")
            else:
                st.success("""âœ… **ä½é£é™©ï¼šå»ºè®®å¸¸è§„å¥åº·ç®¡ç†**""")
                st.write("- æ¯å¹´ä½“æ£€ä¸€æ¬¡")
                st.write("- ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼")
                st.write("- é¢„é˜²æ€§å¥åº·æŒ‡å¯¼")
            
            # SHAPå¯è§†åŒ–
            if explainer is not None:
                try:
                    shap_values = explainer.shap_values(processed_data)
                    expected_value = explainer.expected_value
                    
                    # åˆ›å»ºSHAPå†³ç­–å›¾
                    st.subheader(f"ğŸ§  å†³ç­–ä¾æ®åˆ†æï¼ˆ{'è¡°å¼±' if prediction == 1 else 'éè¡°å¼±'}ç±»ï¼‰")
                    
                    # ä½¿ç”¨ç€‘å¸ƒå›¾
                    plt.figure(figsize=(12, 8))
                    shap.plots.waterfall(shap.Explanation(
                        values=shap_values[0], 
                        base_values=expected_value,
                        feature_names=[f'feature_{i}' for i in range(processed_data.shape[1])],
                        data=processed_data[0]
                    ))
                    st.pyplot(plt.gcf(), clear_figure=True)
                    plt.close()
                    
                    st.markdown("""
                    **å›¾ä¾‹è¯´æ˜:**
                    - ğŸ“Š **æ¡å½¢å›¾**ï¼šæ˜¾ç¤ºæ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹çš„å½±å“ç¨‹åº¦
                    - â• **æ­£å€¼**ï¼šå¢åŠ è¡°å¼±é£é™©çš„ç‰¹å¾
                    - â– **è´Ÿå€¼**ï¼šé™ä½è¡°å¼±é£é™©çš„ç‰¹å¾
                    """)
                    
                except Exception as e:
                    st.warning(f"SHAPå¯è§†åŒ–å¤±è´¥: {str(e)}")
            
        except Exception as e:
            st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

# æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
with st.expander("â„¹ï¸ ç³»ç»ŸçŠ¶æ€"):
    st.write(f"**æ¨¡å‹åŠ è½½:** {'âœ… æˆåŠŸ' if 'model' in components else 'âŒ å¤±è´¥'}")
    st.write(f"**é¢„å¤„ç†å™¨:** {'âœ… å¤–éƒ¨' if components.get('preprocessor') else 'ğŸ”„ å†…ç½®'}")
    st.write(f"**é¢„æµ‹å™¨:** {'âœ… å¤–éƒ¨' if components.get('predictor') else 'ğŸ”„ é»˜è®¤é˜ˆå€¼0.57'}")
    st.write(f"**SHAPè§£é‡Šå™¨:** {'âœ… å¯ç”¨' if explainer else 'âŒ ä¸å¯ç”¨'}")

# é¡µè„š
st.markdown("---")
st.caption("Â©2025 KOAé¢„æµ‹ç³»ç»Ÿ | ä»…ä¾›ä¸´åºŠå‚è€ƒ")
